{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wY6Ek0L5c890"
      },
      "outputs": [],
      "source": [
        "# Install Python libraries\n",
        "!pip install transformers torch emoji\n",
        "!pip install mysql-connector-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Python libraries\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "import emoji\n",
        "import pandas as pd\n",
        "import mysql.connector\n",
        "import warnings\n",
        "from google.colab import files\n",
        "import time\n",
        "import openpyxl\n",
        "from google.colab import auth\n",
        "import gspread\n",
        "from google.auth import default\n",
        "from sqlalchemy import create_engine"
      ],
      "metadata": {
        "id": "Rd9xnkGZJj1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RDS MySQL connection details\n"
      ],
      "metadata": {
        "id": "5LinD67-hr9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Twitter sentiment model\n",
        "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# MySQL connection\n",
        "conn = mysql.connector.connect(\n",
        "    host=DB_HOST,\n",
        "    user=DB_USER,\n",
        "    password=DB_PASSWORD,\n",
        "    database=DB_NAME\n",
        ")\n",
        "cursor = conn.cursor()\n",
        "cursor.execute(\"SELECT * FROM reddit_posts;\")\n",
        "\n",
        "columns = [desc[0] for desc in cursor.description]\n",
        "data = cursor.fetchall()\n",
        "df = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "cursor.close()\n",
        "conn.close()\n",
        "\n",
        "# Prepare for sentiment analysis\n",
        "texts = df['title'].dropna().tolist()\n",
        "\n",
        "# Preprocess and analyze\n",
        "def preprocess(text):\n",
        "    return emoji.demojize(text).replace('\\n', ' ').strip()\n",
        "\n",
        "results = []\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    post_id = row['id']\n",
        "    title = row['title']\n",
        "    if pd.isna(title):\n",
        "        continue\n",
        "    cleaned = preprocess(title)\n",
        "    result = sentiment_pipeline(cleaned)[0]\n",
        "    label_map = {\n",
        "        'LABEL_0': 'Negative',\n",
        "        'LABEL_1': 'Neutral',\n",
        "        'LABEL_2': 'Positive'\n",
        "    }\n",
        "    sentiment = label_map[result['label']]\n",
        "    score = round(result['score'], 4)\n",
        "    results.append({\n",
        "        'id': post_id,\n",
        "        'title': title,\n",
        "        'sentiment': sentiment,\n",
        "        'confidence': score\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame\n",
        "sentiment_df = pd.DataFrame(results)\n",
        "\n",
        "db_url = f\"mysql+mysqlconnector://{DB_USER}:{DB_PASSWORD}@{DB_HOST}/{DB_NAME}\"\n",
        "engine = create_engine(db_url)\n",
        "\n",
        "sentiment_df.to_sql(name='reddit_posts_sentiment', con=engine, if_exists='replace', index=False)\n",
        "\n",
        "print(\"Sentiment results written to 'reddit_posts_sentiment' table.\")\n",
        "# Preview\n",
        "print(sentiment_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XcCVcWVdejS",
        "outputId": "151c3181-4924-4f7c-e59d-03a11e143551"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment results written to 'reddit_posts_sentiment' table.\n",
            "        id                                              title sentiment  \\\n",
            "0  10022mt  u thought I really really really really really...   Neutral   \n",
            "1  1002enq  Lego Pere Marquette 1225 with Polar Express le...   Neutral   \n",
            "2  1006v2f                                              2022…   Neutral   \n",
            "3  10096c5  This is working, what's the worst that could h...   Neutral   \n",
            "4  100bywo                                     Happy New Year  Positive   \n",
            "\n",
            "   confidence  \n",
            "0      0.5433  \n",
            "1      0.9108  \n",
            "2      0.7021  \n",
            "3      0.5508  \n",
            "4      0.9688  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Query result set\n",
        "db_url = f\"mysql+mysqlconnector://{DB_USER}:{DB_PASSWORD}@{DB_HOST}/{DB_NAME}\"\n",
        "engine = create_engine(db_url)\n",
        "\n",
        "# Run query and load into DataFrame\n",
        "query = \"SELECT * FROM reddit_posts_sentiment;\"\n",
        "df_sentiment = pd.read_sql(query, engine)\n",
        "\n",
        "# Preview result\n",
        "print(df_sentiment.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_-PKoJXJM52",
        "outputId": "49dac196-9c26-48aa-b246-c07236ad2a72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        id                                              title sentiment  \\\n",
            "0  10022mt  u thought I really really really really really...   Neutral   \n",
            "1  1002enq  Lego Pere Marquette 1225 with Polar Express le...   Neutral   \n",
            "2  1006v2f                                              2022…   Neutral   \n",
            "3  10096c5  This is working, what's the worst that could h...   Neutral   \n",
            "4  100bywo                                     Happy New Year  Positive   \n",
            "\n",
            "   confidence  \n",
            "0      0.5433  \n",
            "1      0.9108  \n",
            "2      0.7021  \n",
            "3      0.5508  \n",
            "4      0.9688  \n"
          ]
        }
      ]
    }
  ]
}