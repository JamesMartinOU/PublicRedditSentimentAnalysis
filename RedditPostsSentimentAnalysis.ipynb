{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3M6FnSeTnNZHXO6s+5lMa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JamesMartinOU/PublicRedditSentimentAnalysis/blob/main/RedditPostsSentimentAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wY6Ek0L5c890"
      },
      "outputs": [],
      "source": [
        "# Install Python libraries\n",
        "!pip install transformers torch emoji\n",
        "!pip install mysql-connector-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Python libraries\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "import emoji\n",
        "import pandas as pd\n",
        "import mysql.connector\n",
        "import warnings\n",
        "from google.colab import files\n",
        "import time\n",
        "import openpyxl\n",
        "from google.colab import auth\n",
        "import gspread\n",
        "from google.auth import default\n",
        "from sqlalchemy import create_engine"
      ],
      "metadata": {
        "id": "Rd9xnkGZJj1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RDS MySQL connection details\n"
      ],
      "metadata": {
        "id": "5LinD67-hr9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Twitter sentiment model\n",
        "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# MySQL connection\n",
        "conn = mysql.connector.connect(\n",
        "    host=DB_HOST,\n",
        "    user=DB_USER,\n",
        "    password=DB_PASSWORD,\n",
        "    database=DB_NAME\n",
        ")\n",
        "cursor = conn.cursor()\n",
        "cursor.execute(\"SELECT * FROM reddit_posts;\")\n",
        "\n",
        "columns = [desc[0] for desc in cursor.description]\n",
        "data = cursor.fetchall()\n",
        "df = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "cursor.close()\n",
        "conn.close()\n",
        "\n",
        "# Prepare for sentiment analysis\n",
        "texts = df['title'].dropna().tolist()\n",
        "\n",
        "# Preprocess and analyze\n",
        "def preprocess(text):\n",
        "    return emoji.demojize(text).replace('\\n', ' ').strip()\n",
        "\n",
        "results = []\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    post_id = row['id']\n",
        "    title = row['title']\n",
        "    if pd.isna(title):\n",
        "        continue\n",
        "    cleaned = preprocess(title)\n",
        "    result = sentiment_pipeline(cleaned)[0]\n",
        "    label_map = {\n",
        "        'LABEL_0': 'Negative',\n",
        "        'LABEL_1': 'Neutral',\n",
        "        'LABEL_2': 'Positive'\n",
        "    }\n",
        "    sentiment = label_map[result['label']]\n",
        "    score = round(result['score'], 4)\n",
        "    results.append({\n",
        "        'id': post_id,\n",
        "        'title': title,\n",
        "        'sentiment': sentiment,\n",
        "        'confidence': score\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame\n",
        "sentiment_df = pd.DataFrame(results)\n",
        "\n",
        "db_url = f\"mysql+mysqlconnector://{DB_USER}:{DB_PASSWORD}@{DB_HOST}/{DB_NAME}\"\n",
        "engine = create_engine(db_url)\n",
        "\n",
        "sentiment_df.to_sql(name='reddit_posts_sentiment', con=engine, if_exists='replace', index=False)\n",
        "\n",
        "print(\"Sentiment results written to 'reddit_posts_sentiment' table.\")\n",
        "# Preview\n",
        "print(sentiment_df.head())"
      ],
      "metadata": {
        "id": "6XcCVcWVdejS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Query result set\n",
        "db_url = f\"mysql+mysqlconnector://{DB_USER}:{DB_PASSWORD}@{DB_HOST}/{DB_NAME}\"\n",
        "engine = create_engine(db_url)\n",
        "\n",
        "# Run query and load into DataFrame\n",
        "query = \"SELECT * FROM reddit_posts_sentiment;\"\n",
        "df_sentiment = pd.read_sql(query, engine)\n",
        "\n",
        "# Preview result\n",
        "print(df_sentiment.head())"
      ],
      "metadata": {
        "id": "T_-PKoJXJM52"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}